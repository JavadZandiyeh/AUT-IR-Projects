{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MYmYmnT6vWM"
   },
   "source": [
    "# Boolean Query\n",
    "\n",
    "In this notebook, we will implement a Boolean information retrieval model by Elasticsearch.  \n",
    "We have these steps: <br>\n",
    "\n",
    "**1- Connect to the Elasticsearch Cluster and Create an Index <br>\n",
    "2- Indexing Documents <br>\n",
    "3- Boolean Retrieval (Fill where ever it says #TODO in this part)** <br>\n",
    "\n",
    "Let me know if you have any problems with this notebook or implementation. <br>\n",
    "**Telegram**: [@Mohammad_Ardestani4](https://t.me/Mohammad_Ardestani4) <br>\n",
    "**Email**: mjavad.ardestani00@gmial.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e1Ld-wPi9eXy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch==7.13.0 in c:\\users\\javad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (7.13.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in c:\\users\\javad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from elasticsearch==7.13.0) (1.26.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\javad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from elasticsearch==7.13.0) (2020.12.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\javad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\javad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch==7.13.0\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zz8PVXZwOTKg",
    "outputId": "1b6699d5-46a9-4afa-9867-c4959cccf999"
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "import os, json, time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VrkfiwK68K7"
   },
   "source": [
    "## Ignore The Security Warnings\n",
    "Here we ignore the security warnings. It's suggested that you don't run below cell until you ensure that all warnings are about security. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BsAE99xuOTKj"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwRjta2P85gJ"
   },
   "source": [
    "## Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZ38UddzOTKm",
    "outputId": "f8f848e7-58bd-4eae-fd63-fa29ca131044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'content', 'tags', 'date', 'url', 'category'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dataset_path = 'IR_data_news_12k.json'\n",
    "with open(dataset_path) as f:\n",
    "    data = json.load(f)\n",
    "print(data['0'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34HO2cmPOTKo"
   },
   "source": [
    "## Connect to the Elasticsearch Cluster and Create an Index\n",
    "After starting your Elasticsearch on your pc (localhost:9200 is the default), we have to connect to it via the following piece of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "jKxaAaTYOTKq",
    "outputId": "024fb7a3-4ae3-4e59-d6bf-83c6e33f6ed1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True,\n",
       " 'shards_acknowledged': True,\n",
       " 'index': 'my_elastic_index'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'my_elastic_index'\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# Delete index if one does exist\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "\n",
    "es.indices.create(index = index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Cluster Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wzH4AbnGOTKs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'DESKTOP-9SJ4G2F',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'MXj13B4xRqC82nDZvTKp8g',\n",
       " 'version': {'number': '7.4.2',\n",
       "  'build_flavor': 'unknown',\n",
       "  'build_type': 'unknown',\n",
       "  'build_hash': '2f90bbf7b93631e52bafb59b3b049cb44ec25e96',\n",
       "  'build_date': '2019-10-28T20:40:44.881551Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.2.0',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(es.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z2i0tJoOTKv"
   },
   "source": [
    "we can add our documents to created index in two ways:<br>\n",
    "1- one by one in for loop. <br>\n",
    "2- use [Bulk API](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html#:~:text=Bulk%20APIedit,can%20greatly%20increase%20indexing%20speed.), which performs multiple indexing or delete operations in a single API call. This reduces overhead and can significantly increase indexing speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibRuMxh8OTKx"
   },
   "source": [
    "###  for loop by es.index \n",
    "**You dont have to run this cell**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E81WiFk2OTKz",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(data))):\n",
    "#     es.index(index = index_name, id=i, document=data[str(i)])\n",
    "#     i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiv35Uj3OTK2"
   },
   "source": [
    "###  Bulk API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qt1XZ-BaOTK4"
   },
   "outputs": [],
   "source": [
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "def bulk_sync():\n",
    "    actions = [\n",
    "        {\n",
    "            '_index': index_name,\n",
    "            '_id': doc_id,\n",
    "            '_source': doc\n",
    "        } for doc_id,doc in data.items()\n",
    "    ]\n",
    "    bulk(es, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QUuoIuvlOTK5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing all documents took about 31.43 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "bulk_sync()\n",
    "end = time.time()\n",
    "print(\"Indexing all documents took about {:.2f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHIPOwW1OTK7"
   },
   "source": [
    "### check index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hg8OYRf_OTK8",
    "outputId": "259e5c05-4b2e-40c6-8c9f-6aa9b41f4563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 12202,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index = index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PDnW1SnOTK-"
   },
   "source": [
    "## Boolean Retrieval "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTtzPkLCOTK-"
   },
   "source": [
    "### Bool Query Structure\n",
    "\n",
    "It is built using one or more boolean clauses, each clause with a typed occurrence. The occurrence types are:\n",
    "\n",
    "**must**: The clause (query) must appear in matching documents and will contribute to the score.\n",
    "<br><br>\n",
    "**filter**: The clause (query) must appear in matching documents. However unlike must the score of the query will be ignored. Filter clauses are executed in filter context, meaning that scoring is ignored and clauses are considered for caching.\n",
    "<br><br>\n",
    "**should**: The clause (query) should appear in the matching document.\n",
    "<br><br>\n",
    "**must_not**: The clause (query) must not appear in the matching documents. Clauses are executed in filter context meaning that scoring is ignored and clauses are considered for caching. Because scoring is ignored, a score of 0 for all documents is returned.\n",
    "\n",
    "For further information, you can read this [Document](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html). \n",
    "\n",
    "###  <span style=\"color:red\"> TODO </span>\n",
    "You should read about [match query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html#match-top-level-params) and [match phrase query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase.html) then complete the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "کوئری خود را وارد کنید: \"تحریم هسته‌ای\" آمریکا ! ایران\n"
     ]
    }
   ],
   "source": [
    "query_json = {\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"should\": [\n",
    "        # {\"match\": {\"content\": {\"query\": \"آمریکا\"}}},\n",
    "        # {\"match_phrase\": {\"content\": {\"query\": \"تحریم هسته‌ای\"}}},\n",
    "      ],\n",
    "      \"must_not\": [\n",
    "        # {\"match\": {\"content\": {\"query\": \"ایران\"}}},\n",
    "      ],\n",
    "    },\n",
    "  }\n",
    "}\n",
    "\n",
    "query = input('کوئری خود را وارد کنید: ')\n",
    "\n",
    "# should -> match_phrases\n",
    "quotations = [i for i in range(len(query)) if query[i] == \"\\\"\"]\n",
    "if len(quotations)%2 == 1: quotations.pop() # odd number of quotations\n",
    "\n",
    "for i in range(0, len(quotations), 2): # save phrases in a list\n",
    "    match_ph = (query[quotations[i]+1:quotations[i+1]])\n",
    "    query_json['query']['bool']['should'].append({\"match_phrase\": {\"content\": {\"query\": match_ph}}})\n",
    "\n",
    "# must_not, should -> match\n",
    "from parsivar import Tokenizer, Normalizer\n",
    "my_normalizer = Normalizer()\n",
    "my_tokenizer = Tokenizer()\n",
    "\n",
    "query_copy = query\n",
    "query_copy = \"\\\"\" + query_copy + \"\\\"\"\n",
    "quotations_copy = [i for i in range(len(query_copy)) if query_copy[i] == \"\\\"\"]\n",
    "for i in range(0, len(quotations_copy), 2):\n",
    "      x = (query_copy[quotations_copy[i]+1:quotations_copy[i+1]])\n",
    "      x1 = my_normalizer.normalize(x)\n",
    "      x2 = my_tokenizer.tokenize_words(x1)\n",
    "      j = 0\n",
    "      while j < len(x2):\n",
    "          if x2[j] == \"!\":\n",
    "            match = x2[j+1]\n",
    "            query_json['query']['bool']['must_not'].append({\"match\": {\"content\": {\"query\": match}}})\n",
    "            j += 2\n",
    "          else:\n",
    "            query_json['query']['bool']['should'].append({\"match\": {\"content\": {\"query\": x2[j]}}})\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"تحریم هسته‌ای\" آمریکا ! ایران\n",
      "{'query': {'bool': {'should': [{'match_phrase': {'content': {'query': 'تحریم هسته\\u200cای'}}}, {'match': {'content': {'query': 'آمریکا'}}}], 'must_not': [{'match': {'content': {'query': 'ایران'}}}]}}}\n"
     ]
    }
   ],
   "source": [
    "print(query)\n",
    "print(query_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqR7SLBVOTLC"
   },
   "source": [
    "### Search query\n",
    "\n",
    "The _source field contains the original JSON document body that was passed at index time. The _source field itself is not indexed (and thus is not searchable), but it is stored so that it can be returned when executing fetch requests, like get or search.\n",
    "\n",
    "For further information, you can read this [Document](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html#search-api-response-body)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "SSrpYB5JOTLC",
    "outputId": "5865f35f-8d44-413f-85cf-2c7e37c4ed7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching documents took about 3.33 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "res = es.search(index=index_name, body=query_json, _source= [\"url\"])\n",
    "res = dict(res)\n",
    "end = time.time()\n",
    "print(\"searching documents took about {:.2f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkHMGaXfOTLD"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "g3sPDdpROTLE",
    "outputId": "92ed7fe8-f69c-4f48-aba5-ca2b4a881968",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 results in 0.882 s: \n",
      "https://www.farsnews.ir/news/14001214000789/نماینده-کلیمیان-در-مجلس-دهم--کارتل‌ها-بر-تصمیمات-هیأت-حاکمه-آمریکا\n",
      "https://www.farsnews.ir/news/14001217000665/خباثت‌های-آمریکا-در-برجام-روسیه-و-چین-را-هم-به-این-کشور-بدبین-کرد\n",
      "https://www.farsnews.ir/news/14001213000089/آمریکا-با-بحران‌آفرینی-به-حیات-خود-ادامه-می-دهد\n",
      "https://www.farsnews.ir/news/14001211000321/آمریکا-دولت‌های-متحد-خود-را-در-زمان-اضطرار-تنها-می‌گذارد\n",
      "https://www.farsnews.ir/news/14001211000898/سود-مافیای-اسلحه‌سازی-آمریکا-در-ناامن-بودن-جهان-است\n",
      "https://www.farsnews.ir/news/14001214000825/آمریکا-رژیمی-مافیایی-است-و-مردم-در-تصمیمات-حاکمان-آن-جایگاهی-ندارند\n",
      "https://www.farsnews.ir/news/14001212000725/آمریکا-برای-فروش-تسلیحات-خود-به-ایجادناامنی-و-بحران‌آفرینی-نیاز-دارد\n",
      "https://www.farsnews.ir/news/14001204000444/۲۸-آمریکایی-در-جام-یاشاردوغو-جردن-باروز-هم-می‌آید\n",
      "https://www.farsnews.ir/news/14001213000328/کارتل‌های-اقتصادی-رؤسای-جمهور-آمریکا-را-تعیین-می‌کنند\n",
      "https://www.farsnews.ir/news/14001211000220/نماینده-کلیمیان-در-مجلس-منافع-رژیم-مافیایی-آمریکا-در-ایجاد-ناامنی-است\n"
     ]
    }
   ],
   "source": [
    "print(\"{} results in {} s: \".format(res['hits']['total']['value'] ,res['took']/1000))\n",
    "for doc in res['hits']['hits']:\n",
    "    print(doc['_source']['url'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "boolean_query.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "cacd30a67e9c54f76d0487f5b076fd54b14c281e005077295ff3a8a79ca91f14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
